{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4.텐서보드를이용한_데이터플로우그래프_시각화.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPkEsE1+zGy5hI/hv8m1JSz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"w6VtUZJairyD"},"source":["# 개요"]},{"cell_type":"markdown","metadata":{"id":"iPSujI5ki9l-"},"source":["- 텐서플로우에서 데이터 플로우 그래프 및 기타 부수적인 시각화 작업을 할수 있는 장치\n","- 텐서보드 \n","  - 코랩용\n","  - 아나콘다 베이스(일반 파이썬) "]},{"cell_type":"markdown","metadata":{"id":"8gac8cmMisJo"},"source":["# 텐서보드 모듈 가져오기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"sPGE_cl0jhoo","executionInfo":{"status":"ok","timestamp":1630471570896,"user_tz":-540,"elapsed":5664,"user":{"displayName":"bs edu","photoUrl":"","userId":"16292712382043478147"}},"outputId":"258a7ab2-f166-46d8-9098-ff63fdbe5bcc"},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","tf.__version__"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.15.2'"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUzZ3u5qkMp8","executionInfo":{"status":"ok","timestamp":1630471576473,"user_tz":-540,"elapsed":5584,"user":{"displayName":"bs edu","photoUrl":"","userId":"16292712382043478147"}},"outputId":"5af77b8a-fa08-4dba-86cf-02f8bd5d23ec"},"source":["#%pip list\n","\n","# tensorboard                   1.15.0\n","# 코랩용 텐서보드 설치\n","!pip install tensorboardcolab"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorboardcolab\n","  Downloading tensorboardcolab-0.0.22.tar.gz (2.5 kB)\n","Building wheels for collected packages: tensorboardcolab\n","  Building wheel for tensorboardcolab (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorboardcolab: filename=tensorboardcolab-0.0.22-py3-none-any.whl size=3857 sha256=1237ea25714ed11c3897db340240d35121fb25cec6697ad733dece98702c8719\n","  Stored in directory: /root/.cache/pip/wheels/69/4e/4a/1c6c267395cb10edded1050df12af165d3254cfce324e80941\n","Successfully built tensorboardcolab\n","Installing collected packages: tensorboardcolab\n","Successfully installed tensorboardcolab-0.0.22\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vyoz-GGtkZKP","executionInfo":{"status":"ok","timestamp":1630471576474,"user_tz":-540,"elapsed":9,"user":{"displayName":"bs edu","photoUrl":"","userId":"16292712382043478147"}},"outputId":"6f590c56-3dd8-45aa-bc10-8c1f90f0e3a0"},"source":["# 텐서 보드 가져오기\n","from tensorboardcolab import *"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]}]},{"cell_type":"code","metadata":{"id":"DRlmowHIlJbX"},"source":["import os, shutil"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-M7SShF1isaC"},"source":["# 텐서보드 설정"]},{"cell_type":"code","metadata":{"id":"xQQ364Mkljtu"},"source":["# 텐서보드에 필요한 데이터를 저장하는 공간 지정\n","try:\n","  # 기존 자료 제거\n","  shutil.rmtree( './Graph', ignore_errors=True )\n","  # 생성\n","  os.mkdir('./Graph')\n","except Exception as e:\n","  print( e )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o5eAo7zHl8h9","executionInfo":{"status":"ok","timestamp":1630471593506,"user_tz":-540,"elapsed":17037,"user":{"displayName":"bs edu","photoUrl":"","userId":"16292712382043478147"}},"outputId":"b1ca6a89-c893-45ed-a43d-85a251a47cd7"},"source":["# 코랩에 사용하는 텐서보드  생성\n","tbc = TensorBoardColab()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wait for 8 seconds...\n","TensorBoard link:\n","https://4899-35-202-100-97.ngrok.io\n"]}]},{"cell_type":"markdown","metadata":{"id":"bYOFStN8isrb"},"source":["# 훈련 및 시각화"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Zj9EEq-i1Kf","executionInfo":{"status":"ok","timestamp":1630471596840,"user_tz":-540,"elapsed":3338,"user":{"displayName":"bs edu","photoUrl":"","userId":"16292712382043478147"}},"outputId":"8a2d5d3d-1663-4b3e-f596-eafdd6b7496c"},"source":["# part1 : Data Flow Graph 생성\n","from tensorflow.examples.tutorials.mnist import input_data\n","import numpy as np\n","\n","mnist     = input_data.read_data_sets( './data/mnist/', one_hot=True )\n","PIXEL     = mnist.train.images.shape[1]\n","PIXEL_H   = int( np.sqrt(PIXEL) )\n","PIXEL_W   = PIXEL_H\n","LABEL_NUM = mnist.train.labels.shape[-1]\n","\n","x         = tf.placeholder( tf.float32, shape=(None, PIXEL), name='x' )\n","\n","def make_FilterByWeight( name, shape ):  \n","  name = f'{name}_W'  \n","  tmp  = tf.truncated_normal(  shape, stddev=0.1 )  \n","  W    = tf.Variable( initial_value=tmp, name=name )\n","  return W;\n","def make_Bias( name, shape, value ):  \n","  name = f'{name}_b'  \n","  tmp  = tf.constant( value, shape=shape )  \n","  b    = tf.Variable( initial_value=tmp, name=name )\n","  return b\n","def make_conv2d( name, x, W ):  \n","  return tf.nn.conv2d(  x, filter=W, strides=[1,1,1,1], padding='SAME', name=name )\n","\n","layer_name    = 'conv_1f'\n","with tf.name_scope( layer_name ) as scope:\n","  conv_1f_W   = make_FilterByWeight( layer_name, (5,5,1,32) )\n","  conv_1f_b   = make_Bias( layer_name, shape=(32,), value=0.1 )\n","  x_4d        = tf.reshape( x, ( -1, PIXEL_H, PIXEL_W, 1) )\n","  conv_1f     = make_conv2d( layer_name, x_4d,  conv_1f_W ) + conv_1f_b\n","  act_conv_1f = tf.nn.relu( conv_1f )\n","\n","def make_MaxPooling( name, x ):\n","  name        = f'{name}_max'\n","  return tf.nn.max_pool(  x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME', name=name)  \n","\n","layer_name    = 'pooling_1f'\n","with tf.name_scope( layer_name ) as scope:  \n","  pool_1f     = make_MaxPooling( layer_name, act_conv_1f )\n","\n","layer_name     = 'conv_2f'\n","with tf.name_scope( layer_name ) as scope:  \n","  conv_2f_W    = make_FilterByWeight( layer_name, (5,5,32,32*2) )\n","  conv_2f_b    = make_Bias( layer_name, shape=(32*2,), value=0.1 )  \n","  conv_2f      = make_conv2d( layer_name, pool_1f,  conv_2f_W ) + conv_2f_b\n","  act_conv_2f  = tf.nn.relu( conv_2f )\n","\n","layer_name     = 'pooling_2f'\n","with tf.name_scope( layer_name ) as scope:  \n","  pool_2f      = make_MaxPooling( layer_name, act_conv_2f )\n","\n","layer_name = 'fc'\n","with tf.name_scope( layer_name ) as scope:  \n","  _, h, w, ch = pool_2f.shape\n","  in_channels = h * w * ch\n","  ch_size     = 1024\n","  tmp_x       = tf.reshape( pool_2f, ( -1,  in_channels) )\n","  fc_W        = make_FilterByWeight( layer_name, (in_channels, ch_size) )\n","  fc_b        = make_Bias( layer_name, (ch_size,), 0.1 )\n","  fc          = tf.matmul( tmp_x, fc_W ) + fc_b\n","  act_fc      = tf.nn.relu( fc )\n","\n","layer_name        = 'act_fc_dropout'\n","with tf.name_scope( layer_name ) as scope:  \n","  keep_prob       = tf.placeholder( tf.float32 )\n","  act_fc_dropout  = tf.nn.dropout( act_fc, rate=1-keep_prob ) \n","\n","layer_name = 'output'\n","with tf.name_scope( layer_name ) as scope:  \n","  _, in_ch = act_fc_dropout.shape\n","  y_W      = make_FilterByWeight( layer_name, ( in_ch, LABEL_NUM )  )\n","  y_b      = make_Bias( layer_name,  (LABEL_NUM,), 0.1 )\n","  y_conv   = tf.matmul( act_fc_dropout, y_W ) + y_b\n","  y_conv   = tf.nn.softmax( y_conv )\n","\n","y_ = tf.placeholder( tf.float32, shape=(None, LABEL_NUM), name='y_' )\n","\n","layer_name      = 'loss'\n","with tf.name_scope( layer_name ) as scope:\n","  cross_entropy = -tf.reduce_sum( y_ * tf.log( y_conv )  )\n","\n","layer_name = 'adam'\n","with tf.name_scope( layer_name ) as scope:  \n","  optimzer = tf.train.AdamOptimizer()  \n","  train    = optimzer.minimize( cross_entropy )\n","\n","layer_name = 'predict'\n","with tf.name_scope( layer_name ) as scope:\n","  predict  = tf.equal( tf.argmax( y_conv, 1 ) , tf.argmax( y_, 1 ) )\n","  accuracy = tf.reduce_mean( tf.cast( predict, tf.float32 ) )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From <ipython-input-7-1e5e7b2c044e>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please write your own downloading logic.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use urllib or similar directly.\n","Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting ./data/mnist/train-images-idx3-ubyte.gz\n","Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.data to implement this functionality.\n","Extracting ./data/mnist/train-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tf.one_hot on tensors.\n","Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n","Extracting ./data/mnist/t10k-images-idx3-ubyte.gz\n","Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n","Extracting ./data/mnist/t10k-labels-idx1-ubyte.gz\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zloM4LinMff","executionInfo":{"status":"ok","timestamp":1630471640838,"user_tz":-540,"elapsed":44011,"user":{"displayName":"bs edu","photoUrl":"","userId":"16292712382043478147"}},"outputId":"31e9d92a-16d7-4831-89c7-10fdbcbc46a9"},"source":["# part2 : 실제 학습/평가 수행\n","def make_Feed_Dict( x_data, labels, prob ):    \n","  return {\n","      x:x_data,\n","      y_:labels,\n","      keep_prob:prob\n","  }\n","\n","with tf.device('/device:GPU:0'):\n","  with tf.Session() as sess:\n","    TRAIN_COUNT  = 3000\n","    BATCH_SIZE   = 50    \n","    VERBOSE_TERM = 100\n","    sess.run( tf.global_variables_initializer() )  \n","    test_fd = make_Feed_Dict( mnist.test.images,  mnist.test.labels, 1.0 )\n","    for step in range( TRAIN_COUNT ):\n","      batch = mnist.train.next_batch( BATCH_SIZE )        \n","      train_fd = make_Feed_Dict( batch[0], batch[1], 0.1 )\n","      acc, _, loss_log = sess.run( [accuracy, train, cross_entropy] , feed_dict=train_fd )\n","      #loss_logs.append( loss_log )\n","      if step % VERBOSE_TERM == 0:      \n","        acc = sess.run( accuracy, feed_dict=test_fd )\n","        print( f'step={step:4} acc={acc:20}  loss={loss_log:20}' )          \n","      \n","    acc = sess.run( accuracy, feed_dict=test_fd )\n","    print( f'step={step:4} acc={acc:20}  loss={loss_log:20}' )\n","    \n","    # 텐서보드 기록 작업\n","    writer = tbc.get_writer()\n","    writer.add_graph( sess.graph )\n","    writer.flush()\n","\n","# tbc 닫기\n","tbc.close()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["step=   0 acc= 0.09799999743700027  loss=                 nan\n","step= 100 acc= 0.09799999743700027  loss=                 nan\n","step= 200 acc= 0.09799999743700027  loss=                 nan\n","step= 300 acc= 0.09799999743700027  loss=                 nan\n","step= 400 acc= 0.09799999743700027  loss=                 nan\n","step= 500 acc= 0.09799999743700027  loss=                 nan\n","step= 600 acc= 0.09799999743700027  loss=                 nan\n","step= 700 acc= 0.09799999743700027  loss=                 nan\n","step= 800 acc= 0.09799999743700027  loss=                 nan\n","step= 900 acc= 0.09799999743700027  loss=                 nan\n","step=1000 acc= 0.09799999743700027  loss=                 nan\n","step=1100 acc= 0.09799999743700027  loss=                 nan\n","step=1200 acc= 0.09799999743700027  loss=                 nan\n","step=1300 acc= 0.09799999743700027  loss=                 nan\n","step=1400 acc= 0.09799999743700027  loss=                 nan\n","step=1500 acc= 0.09799999743700027  loss=                 nan\n","step=1600 acc= 0.09799999743700027  loss=                 nan\n","step=1700 acc= 0.09799999743700027  loss=                 nan\n","step=1800 acc= 0.09799999743700027  loss=                 nan\n","step=1900 acc= 0.09799999743700027  loss=                 nan\n","step=2000 acc= 0.09799999743700027  loss=                 nan\n","step=2100 acc= 0.09799999743700027  loss=                 nan\n","step=2200 acc= 0.09799999743700027  loss=                 nan\n","step=2300 acc= 0.09799999743700027  loss=                 nan\n","step=2400 acc= 0.09799999743700027  loss=                 nan\n","step=2500 acc= 0.09799999743700027  loss=                 nan\n","step=2600 acc= 0.09799999743700027  loss=                 nan\n","step=2700 acc= 0.09799999743700027  loss=                 nan\n","step=2800 acc= 0.09799999743700027  loss=                 nan\n","step=2900 acc= 0.09799999743700027  loss=                 nan\n","step=2999 acc= 0.09799999743700027  loss=                 nan\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorboardcolab/core.py:49: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n"]}]}]}